{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb299f82-f4b1-4f85-9195-07724f6dd4cb",
   "metadata": {},
   "source": [
    "# RAG Architecture Sample in Python (Azure AI Search)\n",
    "여기서는 아래 이미지와 같은 RAG 아키텍처를 만들어 볼 것이다.\n",
    "\n",
    "<img src=\"./images/02_001.png\" width=\"70%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c68a5b",
   "metadata": {},
   "source": [
    "# 사전 준비\n",
    "이 파이썬 예제를 실행하려면 다음과 같은 환경이 필요하다:\n",
    "- Azure AI Search 리소스의 엔드포인트 및 쿼리 API 키\n",
    "- Azure OpenAI Service를 사용할 수 있는 [승인 완료](https://aka.ms/oai/access)된 Azure 구독\n",
    "- Azure OpenAI Service에 배포된 `text-embedding-ada-002` Embeddings 모델. 이 모델의 API 버전은 `2023-05-15`을 사용했다. 배포 이름은 모델 이름과 동일하게 `text-embedding-ada-002`로 명명했다.\n",
    "- Azure OpenAI Service 연동 및 모델 정보\n",
    "  - OpenAI API 키\n",
    "  - OpenAI Embeddings 모델의 배포 이름\n",
    "  - OpenAI API 버전\n",
    "- Python (이 예제는 버전 3.10.x로 테스트 했다.)\n",
    "\n",
    "이 예제에서는 Visual Studio Code와 [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter)를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c8bef",
   "metadata": {},
   "source": [
    "## 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d9bbd-e2b9-451a-a872-56f19430d0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install azure-search-documents==11.4.0\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ef945-8aa3-4538-8bf7-662c01bdf397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import azure.search.documents\n",
    "azure.search.documents.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524420cf",
   "metadata": {},
   "source": [
    "## 라이브러리 및 환경변수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c62e8d-9891-4fde-a989-9bb040e1558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient, SearchIndexingBufferedSender  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryCaptionResult,\n",
    "    QueryAnswerResult,\n",
    "    SemanticErrorMode,\n",
    "    SemanticErrorReason,\n",
    "    SemanticSearchResultsType,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    VectorQuery,\n",
    "    VectorFilterMode,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c014e02",
   "metadata": {},
   "source": [
    "## Azure AI Search 연동 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d5c38-7c3d-4849-8079-6f4bcc144a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_endpoint: str = \"<Your search service endpoint>\"\n",
    "service_query_key: str = \"<Your search service query key>\"\n",
    "index_name: str = \"gptkbindex\" # 자동 구축시 기본으로 설정\n",
    "\n",
    "credential = AzureKeyCredential(service_query_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b043a-044b-458e-9626-7c4cda992103",
   "metadata": {},
   "source": [
    "## Azure OpenAI 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa9e2f-58ba-427d-9634-2d83bff3ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_KEY = \"Your OpenAI API Key\"\n",
    "AZURE_OPENAI_ENDPOINT = \"https://<Your OpenAI Service>.openai.azure.com/\"\n",
    "AZURE_OPENAI_CHATGPT_DEPLOYMENT = \"chat\" # 자동 구축시 기본으로 설정\n",
    "AZURE_OPENAI_EMB_DEPLOYMENT=\"embedding\" # 자동 구축시 기본으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd993d8-5d4b-4c58-a793-709f58731a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from openai.types.chat import (\n",
    "    ChatCompletion,\n",
    "    ChatCompletionChunk,\n",
    ")\n",
    "\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "  api_key = AZURE_OPENAI_API_KEY,  \n",
    "  api_version = \"2024-02-01\",\n",
    "  azure_endpoint = AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# title 필드와 content 필드의 Embeddings를 생성하는 함수\n",
    "def generate_embeddings(text, model=AZURE_OPENAI_EMB_DEPLOYMENT):\n",
    "    return openai_client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e42480-7e59-43c0-8834-30724d4a57db",
   "metadata": {},
   "source": [
    "# 1. 검색 쿼리 생성\n",
    "최신 질문과 채팅 이력을 기반으로 프롬프트를 작성하며 GPT-3.5 Turbo 모델을 사용하여 검색 쿼리를 생성한다. 검색 쿼리의 형식을 맞추기 위해 Few-shot 예제를 준비하여 정확도를 높였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f54b32-b0a3-44a5-af97-b501d003716e",
   "metadata": {},
   "source": [
    "## 1.1. 시스템 메시지 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936b4a9-67a3-480d-a611-b48f7f1917d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query generation prompt\n",
    "query_prompt_template = \"\"\"\n",
    "다음은 과거 대화 이력과 한국사 지식을 기반으로 질문과 답변을 주고받는 중에 사용자가 새로운 질문을 한 상황이야.\n",
    "과거 대화 이력과 새로운 질문에 기반해서 검색 쿼리를 생성해줘.\n",
    "검색 쿼리에는 인용한 파일이나 문서 이름(예: info.txt 또는 doc.pdf)을 포함해줘.\n",
    "검색 쿼리에는 괄호([] 또는 <<>>) 안에 있는 문자를 포함시켜선 안돼.\n",
    "검색 쿼리를 생성할 수 없으면 숫자 0이라고만 답변해줘.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role': 'system', 'content': query_prompt_template}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc13f7bc-3260-45b6-8ae3-6755dcaa2601",
   "metadata": {},
   "source": [
    "## 1.2. Few-shot 예제 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51bfdf-809b-4d31-a35d-f66f57bae832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot Samples\n",
    "query_prompt_few_shots = [\n",
    "    {'role' : 'user', 'content' : '이순신은 어떤 인물이야?' },\n",
    "    {'role' : 'assistant', 'content' : '이순신 인물 역사' },\n",
    "    {'role' : 'user', 'content' : '이순신의 공적에 대해서 알려줘.' },\n",
    "    {'role' : 'assistant', 'content' : '이순신 인물 공적' }\n",
    "]\n",
    "\n",
    "for shot in query_prompt_few_shots:\n",
    "    messages.append({'role': shot.get('role'), 'content': shot.get('content')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62fa2b5-570c-4f4f-b292-008be1ecd3ef",
   "metadata": {},
   "source": [
    "## 1.3. 사용자의 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca3ecf-2f0d-4cbc-a605-a739f03d31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User query\n",
    "user_q = \"최충헌은 어떤 인물이야?\"\n",
    "messages.append({'role': 'user', 'content': user_q})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51eeae6-2533-4cfc-a8be-592185e0bdac",
   "metadata": {},
   "source": [
    "## 1.4. 전송할 메시지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0a574-45ad-4510-9902-2650e4c06d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8246bf33-5839-41d4-a095-ad611debda69",
   "metadata": {},
   "source": [
    "## 1.5. 검색 쿼리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b35179-98b8-4931-bfc1-c7fca5412896",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion: ChatCompletion = openai_client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "    temperature=0.0,\n",
    "    max_tokens=100,\n",
    "    n=1)\n",
    "\n",
    "query_text = chat_completion.choices[0].message.content\n",
    "print(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaba7e2-ffd5-4768-9f71-1971b2190531",
   "metadata": {},
   "source": [
    "# 2. 검색 인덱스에서 연관 문서 취득(Retrieve)\n",
    "1. 에서 생성한 검색 쿼리를 사용하여 Azure AI Search로 검색을 수행한다. 이 예제에서는 검색 쿼리와 벡터를 조합한 하이브리드 검색을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f6d06-c7f9-4f54-b551-b6b4a11e30c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonewlines(s: str) -> str:\n",
    "    return s.replace('\\n', ' ').replace('\\r', ' ').replace('[', '【').replace(']', '】')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b71864-30e5-4b5b-a9c3-e0706090dca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "docs = search_client.search(\n",
    "    search_text=query_text,\n",
    "    filter=None,\n",
    "    top=3,\n",
    "    vector_queries=[VectorizedQuery(vector=generate_embeddings(query_text), k_nearest_neighbors=3, fields=\"embedding\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dbd839-96be-43a2-bc7d-fcadf4212af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results =[\" SOURCE:\" + doc['sourcepage'] + \": \" + nonewlines(doc['content']) for doc in docs]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b58d3-8a84-4dc5-9a54-2bbbc47215a4",
   "metadata": {},
   "source": [
    "# 3. ChatGPT를 활용한 응답 생성\n",
    "\n",
    "Azure AI Search의 검색 결과나 채팅 이력을 활용해서 콘텍스트나 내용에 알맞은 응답을 생성한다. 이 때, 프롬프트를 활용해서 출처를 출력하도록 지시한다. 출처에는 Azure AI Search의 파일 이름이라는 필드의 값을 사용한다.\n",
    "\n",
    "시스템 메시지의 정확도를 높이기 위해 일부는 영어로 기술한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b790dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System message\n",
    "system_message_chat_conversation = \"\"\"\n",
    "너는 한국의 무신정권 역사에 관한 문제를 답변해주는 역사 교수야. \n",
    "If you cannot guess the answer to a question from the SOURCE, answer \"I don't know\".\n",
    "Answers must be in Korean.\n",
    "\n",
    "# Restrictions\n",
    "- The SOURCE prefix has a colon and actual information after the filename, and each fact used in the response must include the name of the source.\n",
    "- To reference a source, use a square bracket. For example, [info1.txt]. Do not combine sources, but list each source separately. For example, [info1.txt][info2.pdf].\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role': 'system', 'content': system_message_chat_conversation}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49832229-cd31-44ef-8d45-86d1f2827b5e",
   "metadata": {},
   "source": [
    "## 3.1. 콘텍스트 확장(Augument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94762ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User query\n",
    "user_q = \"최충헌은 어떤 인물이야?\"\n",
    "# Context from Azure AI Search\n",
    "context = \"\\n\".join(results)\n",
    "messages.append({'role': 'user', 'content': user_q + \"\\n\\n\" + context}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a7316-c4bb-4fc2-929c-40af1e5b93f2",
   "metadata": {},
   "source": [
    "## 3.2. 전송할 메시지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136dde4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a592af27-6f90-4b5b-b763-846d6aacac53",
   "metadata": {},
   "source": [
    "## 3.3. 응답 생성(Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0753c-8a60-4897-8f3c-e754bff41a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatCompletion으로 응답 생성하기\n",
    "chat_coroutine = openai_client.chat.completions.create(\n",
    "    model=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
    "    messages=messages,\n",
    "    temperature=0.0,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(chat_coroutine.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4682c-a387-4fbb-9060-cc113e9ad034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
