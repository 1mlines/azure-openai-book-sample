{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb299f82-f4b1-4f85-9195-07724f6dd4cb",
   "metadata": {},
   "source": [
    "# 파이썬으로 사용하는 시맨틱 커널(Semantic Kernel in Python)\n",
    "[시맨틱 커널](https://github.com/microsoft/semantic-kernel)(SK)은 마이크로소프트가 공개한 오픈소스로, 대규모 언어 모델(LLM)을 애플리케이션에 빠르고 간단하게 탑재할 수 있는 SDK다. 시맨틱 커널을 사용하면 기존 프로그래밍 언어로 최신 LLM 모델과 프롬프트를 쉽게 다룰 수 있으며 템플릿화, 체인화, 내장 메모리, 플래닝 등의 기능을 제공한다.\n",
    "\n",
    "이 예제 코드는 시맨틱 커널 공식 [Samples](https://github.com/microsoft/semantic-kernel/tree/main/python/samples)에 기반하여 작성한 것이다. Microsoft Learn에 있는 [공식문서](https://learn.microsoft.com/semantic-kernel/overview/)도 참고 바란다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32dd86d",
   "metadata": {},
   "source": [
    "## 사전 준비\n",
    "\n",
    "이 파이썬 예제를 실행하려면 다음과 같은 환경이 필요하다:\n",
    "\n",
    "- Azure OpenAI Service를 사용할 수 있는 [승인 완료](https://aka.ms/oai/access)된 Azure 구독\n",
    "- Azure OpenAI Service에 배포된 GPT-4o 모델\n",
    "- Azure OpenAI Service 연동 및 모델 정보\n",
    "  - OpenAI API 키\n",
    "  - OpenAI GPT-4o 모델의 배포 이름\n",
    "  - OpenAI API 버전\n",
    "- Python (이 예제는 버전 3.12.4로 테스트 했다.)\n",
    "\n",
    "이 예제에서는 Visual Studio Code와 [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter)를 사용한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf5a47a",
   "metadata": {},
   "source": [
    "## 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d9bbd-e2b9-451a-a872-56f19430d0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install semantic-kernel==1.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37ce97",
   "metadata": {},
   "source": [
    "## Azure OpenAI 설정\n",
    "연동을 위해 필요한 정보는 보안을 위해 하드코딩 하지 말고 .env 파일에서 불러오는 것을 권장한다.  \n",
    "- [.env.sample](.env.sample) 파일 이름을 `.env`로 변경하고 필요한 값을 설정한다.\n",
    "\n",
    "### Azure OpenAI 사용시\n",
    "아래 정보가 필요합니다.\n",
    "```\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"...\"\n",
    "```\n",
    "### OpenAI 사용시\n",
    "아래 정보가 필요합니다.\n",
    "```\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "OPENAI_ORG_ID=\"\"\n",
    "OPENAI_CHAT_MODEL_ID=\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AZURE_OPENAI_API_KEY = \"Your OpenAI API Key\"\n",
    "#AZURE_OPENAI_ENDPOINT = \"https://<Your OpenAI Service>.openai.azure.com/\"\n",
    "#AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = \"gpt-4o\"\n",
    "#AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f83eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding, AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "# Azure OpenAI Service 사용 여부\n",
    "useAzureOpenAI = True\n",
    "\n",
    "service_id = None\n",
    "# 시맨틱 커널에서 사용할 OpenAI 서비스 설정\n",
    "if useAzureOpenAI:\n",
    "    service_id = \"azure-openai-chat\"\n",
    "    azure_chat_service = AzureChatCompletion(service_id=service_id)\n",
    "    #azure_text_embedding = AzureTextEmbedding(service_id=service_id)\n",
    "    kernel.add_service(azure_chat_service)\n",
    "    #kernel.add_service(azure_text_embedding)\n",
    "else:\n",
    "    # OpenAI 사용시\n",
    "    service_id = \"openai-chat\"\n",
    "    oai_text_service = OpenAIChatCompletion(service_id=service_id)\n",
    "    kernel.add_service(oai_text_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d15f9b",
   "metadata": {},
   "source": [
    "## 요약\n",
    "프롬프트를 사용해서 콘텐츠를 요약하는 시맨틱 함수를 만들어보자. 이 함수는 요약할 텍스트를 입력받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "다음 설명을 6살인 유치원생도 이해할 수 있게 요약해줘.\n",
    "유치원생이 모르는 단어는 쉬운 단어로 변환해줘.\n",
    "\n",
    "{{$input}}\n",
    "\"\"\"\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings, OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    summarize_settings = AzureChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        max_tokens=400,\n",
    "        temperature=0.0,\n",
    "        top_p=0.5,\n",
    "    )\n",
    "else:\n",
    "    # OpenAI 사용시\n",
    "    summarize_settings = OpenAIChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        max_tokens=400,\n",
    "        temperature=0.0,\n",
    "        top_p=0.5,\n",
    "    )\n",
    "    \n",
    "summarize_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"summarize\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The user input\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=summarize_settings,\n",
    ")\n",
    "\n",
    "summarize_function = kernel.add_function(\n",
    "    plugin_name=\"summarizePlugin\",\n",
    "    function_name=\"summarizeFunction\",\n",
    "    prompt_template_config=summarize_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa96121",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "중성자별은 초신성 폭발 직후 무거운 별이 중력붕괴하여 만들어진 밀집성의 일종이다.\n",
    "중성자별은 현재까지 관측된 우주의 천체 중 블랙홀 다음으로 밀도가 크다. 거의 12 ~ 13 km의 반지름에 태양의 두 배에 달하는 무거운 질량을 가지고 있다.\n",
    "중성자별은 거의 대부분이 순전하가 없고 양성자보다 약간 더 무거운 핵자인 중성자로 구성되어 있다. \n",
    "이들은 양자 축퇴압에 의해 붕괴되지 않고 유지되는데 이는 매우 뜨거우며 두 개의 중성자(또는 페르미 입자)가 동시에 같은 위치 및 양자 상태를 취할 수 없다는 원리인 파울리 배타 원리를 통해 설명되는 현상이다.\n",
    "중성자별의 질량은 최소 1.1 태양질량에서 3 태양질량(M☉)까지이다. 관측된 것 중 가장 무거운 것은 2.01 M☉이다. \n",
    "중성자별의 표면온도는 보통 ~6×105 K이다. 중성자별의 전체 밀도는 3.7×1017에서 5.9×1017 kg/m3 (태양의 밀도의 2.6×1014 ~ 4.1×1014 배)이다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ccda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "summary = await kernel.invoke(\n",
    "    function=summarize_function, \n",
    "    arguments=KernelArguments(input=input_text)\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7886bcb5",
   "metadata": {},
   "source": [
    "## 채팅 이력을 활용하는 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "너는 한국의 무신정권 역사에 관한 문제를 답변해주는 역사 교수야.\n",
    "명확한 출처를 찾을 수 없거나, 답변할 수 없는 질문에는 '모르겠습니다'라고만 답변해줘.\n",
    "\n",
    "{{$history}}\n",
    "User: {{$user_input}}\n",
    "ChatBot: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a927b7",
   "metadata": {},
   "source": [
    "### 시맨틱 함수로 등록하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if useAzureOpenAI:\n",
    "    chat_settings = AzureChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "        top_p=0.5,\n",
    "    )\n",
    "else:\n",
    "    # OpenAI 사용시\n",
    "    chat_settings = OpenAIChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "        top_p=0.5,\n",
    "    )\n",
    "    \n",
    "chat_config = PromptTemplateConfig(\n",
    "    template=sk_prompt,\n",
    "    name=\"chat\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"user_input\", description=\"The user input\", is_required=True),\n",
    "        InputVariable(name=\"history\", description=\"The conversation history\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=chat_settings,\n",
    ")\n",
    "\n",
    "chat_function = kernel.add_function(\n",
    "    plugin_name=\"chatPlugin\",\n",
    "    function_name=\"chatFunction\",\n",
    "    prompt_template_config=chat_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab03f0",
   "metadata": {},
   "source": [
    "### Chat history\n",
    "\n",
    "ChatHistory는 채팅 이력을 유지하는 데 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d78e04",
   "metadata": {},
   "source": [
    "### 채팅 시작하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15c70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arguments = KernelArguments(user_input=\"최우는 어떤 인물이었나요?\", history=chat_history)\n",
    "bot_answer = await kernel.invoke(\n",
    "    function=chat_function, \n",
    "    arguments=arguments\n",
    ")\n",
    "\n",
    "print(bot_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bbf2a2",
   "metadata": {},
   "source": [
    "### 출력값으로 채팅 이력 업데이트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.add_user_message(arguments['user_input'])\n",
    "chat_history.add_assistant_message(str(bot_answer))\n",
    "print(chat_history.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfe9a9",
   "metadata": {},
   "source": [
    "### 연속적인 채팅이 가능하도록 함수 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat(input_text: str) -> None:\n",
    "    print(f\"User: {input_text}\")\n",
    "\n",
    "    # 사용자가 보낸 메시지를 처리하고 응답을 획득한다.\n",
    "    answer = await kernel.invoke(chat_function, KernelArguments(user_input=input_text, history=chat_history))\n",
    "\n",
    "    # 응답을 표시한다.\n",
    "    print(f\"ChatBot: {answer}\")\n",
    "\n",
    "    # 채팅 이력에 새로 주고 받은 대화를 추가한다.\n",
    "    chat_history.add_user_message(input_text)\n",
    "    chat_history.add_assistant_message(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a42965",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"최우가 간행에 기여한 경전의 이름은?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"최우는 팔만대장경의 간행에 기여했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"팔만대장경은 어떤 책인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"팔만대장경은 고려 시대에 제작된 불교 경전의 목판 인쇄본입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8c597",
   "metadata": {},
   "source": [
    "채팅 후에는 `chat_history`에 쌓인 전체 채팅 이력을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_history.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85b12c",
   "metadata": {},
   "source": [
    "## 플러그인 사용하기\n",
    "파일에서 플러그인과 함수를 불러온다. `./samples/skills/FunSkill` 디렉토리의 구조는 플러그인 구조와 동일하다.\n",
    "\n",
    "https://learn.microsoft.com/semantic-kernel/agents/plugins/?tabs=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c767604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: samples 폴더에 있는 플러그인 사용하기\n",
    "skills_directory = \"./samples/skills\"\n",
    "\n",
    "fun_plugins = kernel.add_plugin(plugin_name=\"FunSkill\", parent_directory=skills_directory)\n",
    "joke_function = fun_plugins[\"Joke\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714d1ef",
   "metadata": {},
   "source": [
    "불러온 함수는 다음과 같이 실행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e88350",
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_arguments = KernelArguments(input=\"선비에 대하여\", style=\"한국의 웃음 코드에 맞게\")\n",
    "\n",
    "result = await kernel.invoke(\n",
    "    function=joke_function, \n",
    "    arguments=joke_arguments\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 실행시\n",
    "response = kernel.invoke_stream(function=joke_function, arguments=joke_arguments)\n",
    "async for message in response:\n",
    "    print(str(message[0]), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba591541",
   "metadata": {},
   "source": [
    "## Sequential 플래너\n",
    "`SequentialPlanner`는 제공된 지시나 질문을 해결하기 위해 단계별 Plan을 생성한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2bbf51",
   "metadata": {},
   "source": [
    "### 계산기 플러그인 불러오기\n",
    "플래너는 사용할 수 있는 플러그인을 알아야 한다. 여기서는 라이브러리에 미리 정의된 `MathPlugin`을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61058b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_plugins.math_plugin import MathPlugin\n",
    "\n",
    "kernel.add_plugin(MathPlugin(), \"math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25be18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planners import SequentialPlanner\n",
    "\n",
    "planner = SequentialPlanner(kernel=kernel, service_id=service_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"202와 990의 합계는 몇이지?\"\n",
    "\n",
    "sequential_plan = await planner.create_plan(goal=ask)\n",
    "\n",
    "print(\"The plan's steps are:\")\n",
    "for step in sequential_plan._steps:\n",
    "    print(\n",
    "        f\"- {step.description.replace('.', '') if step.description else 'No description'} using {step.metadata.fully_qualified_name} with parameters: {step.parameters}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824087d9",
   "metadata": {},
   "source": [
    "`SequentialPlanner`가 질문을 받아 문제를 해결할 방법을 설명하고 있다.\n",
    "위 실행 계획에서 알 수 있듯이 AI는 사용자의 요구를 충족시키기 위해 어떤 함수를 호출해야 하는지를 결정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7995d66c",
   "metadata": {},
   "source": [
    "### 플랜 실행\n",
    "완성된 실행 계획을 실제로 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb8cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await sequential_plan.invoke(kernel)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c34cc",
   "metadata": {},
   "source": [
    "## 플러그인 조합하기\n",
    "### 플래너에 플러그인 제공하기\n",
    "플래너는 사용할 수 있는 플러그인을 알아야 한다. 여기서는 `./samples/skills` 폴더에 정의된 `SummarizeSkill`과 `WriterSkill`을 사용할 수 있도록 불러오고 있다. 여기에는 많은 시맨틱 함수가 포함되어 있으며 플래너는 그 중 일부를 지능적으로 선택한다.\n",
    "\n",
    "네이티브 함수를 포함시킬 수도 있다. 여기서는 `TextSkill`을 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6718f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_plugins.text_plugin import TextPlugin\n",
    "\n",
    "skills_directory = \"./samples/skills/\"\n",
    "summarize_skill = kernel.add_plugin(plugin_name=\"SummarizeSkill\", parent_directory=skills_directory)\n",
    "writer_skill = kernel.add_plugin(plugin_name=\"WriterSkill\", parent_directory=skills_directory)\n",
    "text_skill = kernel.add_plugin(TextPlugin(), \"TextPlugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78358dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"내일은 발렌타인데이라 몇 가지 데이트 아이디어가 필요해.\n",
    "여자친구가 셰익스피어를 좋아하니까 셰익스피어 스타일로 작성해줘.\n",
    "프랑스어로 작성하고, 문자는 대문자로 변경해줘.\n",
    "\"\"\"\n",
    "\n",
    "sequential_plan = await planner.create_plan(goal=ask)\n",
    "print(\"The plan's steps are:\")\n",
    "for step in sequential_plan._steps:\n",
    "    print(\n",
    "        f\"- {step.description.replace('.', '') if step.description else 'No description'} using {step.metadata.fully_qualified_name} with parameters: {step.parameters}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415e966",
   "metadata": {},
   "source": [
    "인라인 플러그인도 정의해서 플래너가 사용할 수 있게 만든다. 반드시 함수 이름과 플러그인 이름을 붙여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78bedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the above in the style of Shakespeare.\n",
    "\"\"\"\n",
    "rewrite_config = PromptTemplateConfig(\n",
    "    template=sk_prompt,\n",
    "    name=\"rewrite\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The user input\", is_required=True)\n",
    "    ],\n",
    "    execution_settings=chat_settings,\n",
    ")\n",
    "shakespeare_function = kernel.add_function(\n",
    "    function_name=\"shakespeare\",\n",
    "    plugin_name=\"ShakespeareSkill\",\n",
    "    prompt_template_config=rewrite_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c1cb1",
   "metadata": {},
   "source": [
    "새 플랜을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f505e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_plan = await planner.create_plan(goal=ask)\n",
    "print(\"The plan's steps are:\")\n",
    "for step in new_plan._steps:\n",
    "    print(\n",
    "        f\"- {step.description.replace('.', '') if step.description else 'No description'} using {step.metadata.fully_qualified_name} with parameters: {step.parameters}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078f393",
   "metadata": {},
   "source": [
    "새로 생성한 플랜을 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93329e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await new_plan.invoke(kernel)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
