{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb299f82-f4b1-4f85-9195-07724f6dd4cb",
   "metadata": {},
   "source": [
    "# Azure OpenAI Service Chat Completion 기초\n",
    "Chat Completion API는 GPT-35-Turbo 혹은 GPT-4 모델과의 대화 용도로 만든 새 API다. 기본적으로 모델을 사용할 때 이 API를 사용하는 것을 권장한다. 또, 새롭게 발표된 GPT-4 모델을 사용할 수 있는 유일한 방법이기도 하다.\n",
    "\n",
    "GPT-35-Turbo와 GPT-4 모델은 대화형 인터페이스에 최적화된 모델이다. 이 모델들의 동작은 이전 GPT-3 모델과는 다르다. 이전 모델에서는 **텍스트 입력-텍스트 출력** 방식을 사용했다. 다시 말해, 이전 모델은 프롬프트의 문자열을 입력받아 해당 프롬프트를 완성한 결과를 반환하는 것이었다. 이와 대조적으로 GPT-35-Turbo와 GPT-4 모델은 **대화 입력-메시지 출력**의 형태로 동작한다. 모델은 채팅 방식의 입력을 예상하고 그 방식에 맞게 작성한 메시지를 반환합니다. 이 방식은 멀티턴 대화용으로 설계된 것이지만 채팅 이외의 상황에도 활용할 수 있다.\n",
    "\n",
    "https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?tabs=python-new&pivots=programming-language-chat-completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c68a5b",
   "metadata": {},
   "source": [
    "## 사전 준비\n",
    "\n",
    "이 파이썬 예제를 실행하려면 다음과 같은 환경이 필요하다:\n",
    "\n",
    "- Azure OpenAI Service를 사용할 수 있는 [승인 완료](https://aka.ms/oai/access)된 Azure 구독\n",
    "- Azure OpenAI Service에 배포된 GPT-3.5 Turbo / GPT-4 모델\n",
    "- Azure OpenAI Service 연동 및 모델 정보\n",
    "  - OpenAI API 키\n",
    "  - OpenAI GPT-3.5 Turbo / GPT-4 모델의 배포 이름\n",
    "  - OpenAI API 버전\n",
    "- Python(이 예제는 버전 3.10.x로 테스트 했다.)\n",
    "\n",
    "이 예제에서는 Visual Studio Code와 [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter)를 사용한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c8bef",
   "metadata": {},
   "source": [
    "## 패키지 설치\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d9bbd-e2b9-451a-a872-56f19430d0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ef945-8aa3-4538-8bf7-662c01bdf397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524420cf",
   "metadata": {},
   "source": [
    "## 라이브러리 및 환경변수 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b043a-044b-458e-9626-7c4cda992103",
   "metadata": {},
   "source": [
    "## Azure OpenAI 설정\n",
    "Azure OpenAI와 연동을 위해 필요한 정보는 보안을 위해 하드코딩 하지 말고 환경변수나 [dotenv](https://pypi.org/project/python-dotenv/)로 불러오는 것을 권장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa9e2f-58ba-427d-9634-2d83bff3ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#os.environ[\"AZURE_OPENAI_API_KEY\"] = \"Your OpenAI API Key\"\n",
    "#os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://<Your OpenAI Service>.openai.azure.com/\"\n",
    "\n",
    "# 이 변수에는 모델을 배포했을 때 설정한 커스텀 이름을 입력한다.\n",
    "#AZURE_OPENAI_DEPLOYMENT_NAME = \"gpt-35-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dafb36d",
   "metadata": {},
   "source": [
    "## Chat Completion 호출\n",
    "GPT-35-Turbo와 GPT-4 모델은 대화 형식 입력에 최적화되어 있다. `messages` 변수는 시스템(`system`), 사용자(`user`), 어시스턴트(`assistant`)로 분류된 역할과 콘텐츠를 가진 딕셔너리 타입 배열로 전달된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd993d8-5d4b-4c58-a793-709f58731a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": \"너는 한국사 질문을 답변해주는 역사 교수야.\"},\n",
    "    {\"role\": \"user\", \"content\": \"정중부, 이고와 함께 무신정변을 일으킨 인물의 이름을 알려줘.\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"), # model = \"deployment_name\"\n",
    "    messages= messages,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b76bd",
   "metadata": {},
   "source": [
    "### 전체 응답 내용 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b603a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86829ece",
   "metadata": {},
   "source": [
    "## 대화 연결하기\n",
    "Chat Completion API는 **Stateless API**이기 때문에 API가 대화 이력을 가지지 않는다. 따라서 대화 이력을 고려한 답변을 받고 싶을 때는 다음과 같이 과거의 대화를 배열에 담아 요청을 보내야 한다.\n",
    "\n",
    "- `\"role\": \"assistant\"`: API의 답변\n",
    "- `\"role\": \"user\"`: 사용자 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": \"너는 한국사 질문을 답변해주는 역사 교수야.\"},\n",
    "    {\"role\": \"user\", \"content\": \"정중부, 이고와 함께 무신정변을 일으킨 인물의 이름을 알려줘.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"정중부, 이고와 함께 무신정변을 일으킨 인물의 이름은 이의방입니다.\"},\n",
    "    {\"role\": \"user\", \"content\": \"이의방의 출신은?\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    messages= messages,\n",
    "    max_tokens=300,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77fecc",
   "metadata": {},
   "source": [
    "## 시스템 메시지\n",
    "시스템 메시지（`system`）는 **배열의 맨 앞**에 위치하며 모델에 최초의 지시를 할당한다. 시스템 메시지에는 다음과 같은 다양한 정보를 지정할 수 있다.\n",
    "\n",
    "- 어시스턴트에 대한 간략한 설명\n",
    "- 어시스턴트의 성격적 특징\n",
    "- 어시스턴트가 지켜야 할 절차 및 규칙\n",
    "- FAQ의 질문 같은 모델이 답변을 생성하기 위해 필요한 데이터나 정보 \n",
    "\n",
    "기본적인 지시를 포함시키거나 용례에 맞게 시스템 메시지를 커스터마이징할 수 있다. 시스템 메시지는 생략할 수도 있지만 최적화된 결과를 얻으려면 최소한 기본적인 지시는 포함시키는 것을 권장한다.\n",
    "\n",
    "### 시스템 메시지 프레임워크 및 템플릿 권장사항\n",
    "https://learn.microsoft.com/azure/ai-services/openai/concepts/system-message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": \"너는 한국사 질문을 답변해주는 역사 교수야. 답변 마지막에는 답변과 연관된 이모티콘을 추가해줘.\"},\n",
    "    {\"role\": \"user\", \"content\": \"이순신이 활약한 전투는?\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    messages= messages,\n",
    "    max_tokens=300,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d782a3e",
   "metadata": {},
   "source": [
    "## 메시지\n",
    "시스템 메시지 뒤에 사용자와 어시스턴트 사이의 대화를 일련의 메시지로 포함시킬 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ae2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": \"너는 한국사 질문을 답변해주는 역사 교수야. 답변 마지막에는 답변과 연관된 이모티콘을 추가해줘.\"},\n",
    "    {\"role\": \"user\", \"content\": \"이순신이 활약한 전투는?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"이순신이 활약한 전투 중에서 가장 유명한 것은 조선 시대의 해상 전투 중 하나인 명량 해전입니다.\"},\n",
    "    {\"role\": \"user\", \"content\": \"명량 해전의 성과를 알려줘.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"), \n",
    "    messages= messages,\n",
    "    max_tokens=300,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28580464",
   "metadata": {},
   "source": [
    "## 지식 추가하기\n",
    "관련된 데이터나 지식을 시스템 메시지에 포함시켜 모델에 추가적인 맥락을 할당할 수 있다. 필요한 정보의 양이 적은 경우에는 시스템 메시지 안에 하드코딩해도 괜찮다. 정보의 양이 많으면 Embeddings API나 Azure AI Search 같은 제품을 사용하여 가장 연관성 높은 정보를 취득할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3666bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "너는 한국사 질문을 답변해주는 역사 교수야.\n",
    "\n",
    "# 규칙\n",
    "- 출처에서 답변을 찾을 수 없으면 '모르겠습니다'라고만 답변해줘.\n",
    "- 출처에 없는 내용을 함부로 추론하지말 것.\n",
    "\n",
    "문맥:\n",
    "###\n",
    "이의방: 이의방.pdf\n",
    "이의방(李義方, 1121년~1175년 1월 19일(율리우스력1월 12일)(1174년 음력 12월 18일)은 고려의 무신이다. 본관은 전주(全州)이다. \n",
    "1170년(고려 의종 23년) 정중부, 이고와 함께 무신정변을 일으켜 응양용호군(鷹揚龍虎軍)의 중랑장(中郞將)에 임명되고,\n",
    "무신정권을 수립한 뒤 대장군(大將軍) 전중감(殿中監) 겸 집주(執奏)에 임명되었다. \n",
    "좌승선(左承宣)으로 조위총의 난을 진압하던 중 정중부의 아들인 정균에 의해 피살되었다.\n",
    "###\n",
    "\n",
    "질문:\n",
    "\"\"\"\n",
    "\n",
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"정중부, 이고와 함께 무신정변을 일으킨 인물의 이름을 알려줘.\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"), \n",
    "    messages= messages,\n",
    "    max_tokens=300,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e9448b",
   "metadata": {},
   "source": [
    "## Chat Completion을 활용한 Few-shot Learning\n",
    "모델에는 몇 가지 예시를 제공할 수 있다. Few-shot Learning 기법을 사용할 때는 프롬프트 형식이 약간 달라진다. 사용자와 어시스턴트 간에 주고 받은 일련의 메시지를 Few-shot 예시로서 프롬프트에 포함시키면 된다. 이 예시들을 활용하면 모델에 특정한 답변 형식을 지정하거나 기본 데이터를 학습시키는 것과 같은 효과를 얻을 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [\n",
    "    {\"role\": \"system\", \"content\": \"너는 한국사 질문을 답변해주는 역사 교수야. 답변 마지막에는 답변과 연관된 이모티콘을 추가해줘.\"},\n",
    "    {\"role\": \"user\", \"content\": \"이순신이 활약한 전투는?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"이순신이 활약한 전투 중에서 가장 유명한 것은 조선 시대의 해상 전투 중 하나인 명량 해전입니다.🚢\"},\n",
    "    {\"role\": \"user\", \"content\": \"명량 해전의 성과를 알려줘.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"이순신 장군은 단 13척의 배로 왜군의 130여 척에 달하는 대규모 함대를 맞아 승리를 이끌었습니다.⚔️🌊\"},\n",
    "    {\"role\": \"user\", \"content\": \"당시 조선 사람들의 생활상을 알려줘.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"왜군의 침입으로 많은 마을과 도시가 파괴되었고, 농경지가 황폐화되었습니다. 이로 인해 식량 부족과 경제적 어려움이 발생했습니다.🏚️🌾\"},\n",
    "    {\"role\": \"user\", \"content\": \"전쟁의 결과는?\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    messages= messages,\n",
    "    max_tokens=300,\n",
    "    temperature=0.0,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ccf89",
   "metadata": {},
   "source": [
    "## 모델별 토큰 계산법\n",
    "OpenAI의 [tiktoken](https://github.com/openai/tiktoken) 라이브러리를 사용해서 토큰수를 계산할 수 있다.\n",
    "tiktoken 라이브러리를 설치하려면 다음 커맨드를 실행한다.\n",
    "\n",
    "`!pip install tiktoken --upgrade`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# \"gpt-3.5-turbo-0613\",\n",
    "# \"gpt-3.5-turbo-16k-0613\",\n",
    "# \"gpt-4-0314\",\n",
    "# \"gpt-4-32k-0314\",\n",
    "# \"gpt-4-0613\",\n",
    "# \"gpt-4-32k-0613\",\n",
    "model = \"gpt-3.5-turbo-0613\"\n",
    "value = \"이순신이 활약한 전투는?\"\n",
    "\n",
    "try:\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "except KeyError:\n",
    "    print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "print(\"Tokens:\",len(value))\n",
    "print(encoding.encode(value))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
